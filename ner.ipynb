{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc = nlp('I have a Golden Retriever at my house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/pipe.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.length_custom_component(doc)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@nlp.component('length_component')\n",
    "def length_custom_component(doc):\n",
    "    print('Doc length:', len(doc))\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe('length_component', first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/component.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pipeline: ['length_component', 'tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "print('New pipeline:', nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc length: 7\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Have you ever seen the rain?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('length_component', <function __main__.length_custom_component(doc)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe('length_component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removal: ['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "print('After removal:', nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical predictions X Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/statXrule.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How training works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/training.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the model weights randomly with <i>nlp.begin_training</i>\n",
    "- Predict a few examples with the current weights by calling <i>nlp.update</i>\n",
    "- Compare prediction with true labels\n",
    "- Calculate how to change weights to improve predictions\n",
    "- Update weights slightly\n",
    "- Go back to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the entity recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each token can only be part of one entity\n",
    "- Examples need to come with an example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/ex1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: <b><i>teach the model to generalize</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/ex2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proglang_patterns = [\n",
    "        [{'LOWER': 'objective'}, {'IS_PUNCT': True, 'OP': '?'}, {'LOWER': 'c'}],\n",
    "        [{'LOWER': 'objectivec'}],\n",
    "        [{'LOWER': 'python'}],\n",
    "        [{'LOWER': {'IN': ['js', 'javascript']}}],\n",
    "        [{'LOWER': 'css'}],\n",
    "        [{'LOWER': 'golang'}],\n",
    "        [{'LOWER': 'c'}],\n",
    "        [{'LOWER': 'c++'}],\n",
    "        [{'LOWER': 'ruby'}],\n",
    "        [{'LOWER': 'java'}],\n",
    "        [{'LOWER': 'php'}],\n",
    "    ]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('proglangs', [*proglang_patterns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data (doc):\n",
    "    detections = [(doc[start:end].start_char, doc[start:end].end_char, 'PROGLANG') for idx, start, end in matcher(doc)]\n",
    "    return (doc.text, {'entities': detections})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I used to program in Java, nowaday I program in C and Python',\n",
       " {'entities': [(21, 25, 'PROGLANG'),\n",
       "   (48, 49, 'PROGLANG'),\n",
       "   (54, 60, 'PROGLANG')]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_train_data(nlp('I used to program in Java, nowaday I program in C and Python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = (pd.read_excel('labels.xlsx', usecols=['Label', 'Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df.loc[:544]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How do I connect to a database and loop over a recordset in C#?',\n",
       "  {'entities': [(60, 61, 'PROGLANG')]}),\n",
       " ('How do I delete a file which is locked by another process in C#?',\n",
       "  {'entities': [(61, 62, 'PROGLANG')]}),\n",
       " ('Good STL-like library for C', {'entities': [(26, 27, 'PROGLANG')]}),\n",
       " ('MySQL/Apache Error in PHP MySQL query',\n",
       "  {'entities': [(22, 25, 'PROGLANG')]})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [parse_train_data(d) for d in nlp.pipe(titles) if len(matcher(d))==1]\n",
    "train_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_nlp(train_data):\n",
    "    nlp = spacy.blank('en')\n",
    "    ner = nlp.add_pipe('ner', last=True)\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - 2021-04-30 17:19:13.076828 {'ner': 100.05899049626645}\n",
      "Losses at iteration 1 - 2021-04-30 17:19:16.389489 {'ner': 1.9396463561209527}\n",
      "Losses at iteration 2 - 2021-04-30 17:19:19.733170 {'ner': 5.885151444565423e-06}\n",
      "Losses at iteration 3 - 2021-04-30 17:19:23.079931 {'ner': 3.456799759239202e-08}\n",
      "Losses at iteration 4 - 2021-04-30 17:19:26.677246 {'ner': 1.1620920524758504e-07}\n",
      "Losses at iteration 5 - 2021-04-30 17:19:30.674881 {'ner': 7.429804436265265e-08}\n",
      "Losses at iteration 6 - 2021-04-30 17:19:34.597493 {'ner': 5.2288994415198204e-08}\n",
      "Losses at iteration 7 - 2021-04-30 17:19:38.609456 {'ner': 2.1583715285186297e-08}\n",
      "Losses at iteration 8 - 2021-04-30 17:19:42.578979 {'ner': 2.8162778239716434e-07}\n",
      "Losses at iteration 9 - 2021-04-30 17:19:46.513748 {'ner': 1.1424396285013037e-08}\n",
      "Losses at iteration 10 - 2021-04-30 17:19:50.315312 {'ner': 3.8140310128773925e-09}\n",
      "Losses at iteration 11 - 2021-04-30 17:19:54.113603 {'ner': 9.608126140298515e-09}\n",
      "Losses at iteration 12 - 2021-04-30 17:19:57.957491 {'ner': 1.9178756157121483e-09}\n",
      "Losses at iteration 13 - 2021-04-30 17:20:02.331313 {'ner': 7.900368768530963e-10}\n",
      "Losses at iteration 14 - 2021-04-30 17:20:06.546149 {'ner': 6.862316181812694e-10}\n",
      "Losses at iteration 15 - 2021-04-30 17:20:10.545641 {'ner': 2.0595243923177976e-09}\n",
      "Losses at iteration 16 - 2021-04-30 17:20:14.455474 {'ner': 4.002704697532174e-09}\n",
      "Losses at iteration 17 - 2021-04-30 17:20:18.369314 {'ner': 1.07251273780112e-09}\n",
      "Losses at iteration 18 - 2021-04-30 17:20:22.295187 {'ner': 4.783157331515702e-09}\n",
      "Losses at iteration 19 - 2021-04-30 17:20:26.295055 {'ner': 8.25666965990152e-09}\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import datetime as dt\n",
    "from spacy.training import Example\n",
    "\n",
    "nlp = create_blank_nlp(train_data)\n",
    "optimizer = nlp.begin_training()  \n",
    "for i in range(20):\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    for text, annotations in train_data:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example], losses=losses)\n",
    "    print(f\"Losses at iteration {i} - {dt.datetime.now()}\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ner', <spacy.pipeline.ner.EntityRecognizer at 0x25308fb06a0>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I should learn \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ruby\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JavaScript\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"I should learn Ruby and JavaScript\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
